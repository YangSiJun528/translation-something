이 글은 [UTF-8 Everywhere](https://utf8everywhere.org/)를 번역한 글입니다. 

DeepSeek R1을 사용하여 번역하였으나, 일부분은 번역자가 다듬었습니다.

원본은 2012년도에 쓰였습니다.   
현재(2025년) Windows의 유니코드 지원은 상당히 개선되었다고 알고 있습니다.

그럼에도 여러 유니코드 인코딩의 특징을 이해하기 좋은 글이라고 생각합니다.

--------------

[UTF-8 Everywhere](#)
=====================

선언문

[이 문서의 목적](#intro)
----------------------------------

> 이 문서는 특수 문자를 포함하고 있습니다. 적절한 렌더링 지원이 없을 경우 물음표, 상자 또는 기타 기호가 보일 수 있습니다.

우리의 목표는 UTF-8 인코딩의 사용과 지원을 촉진하고, 메모리나 디스크에 텍스트 문자열을 저장하거나 통신 및 기타 모든 용도로 사용할 때 기본 선택이 되어야 한다는 것을 설득하는 것입니다. 우리는 우리의 접근 방식이 성능을 향상시키고, 소프트웨어의 복잡성을 줄이며, 많은 유니코드 관련 버그를 예방하는 데 도움이 된다고 믿습니다. 우리는 유니코드(또는 일반적으로 텍스트)의 다른 인코딩들이 최적화의 희귀한 경우에 속하며, 주류 사용자들은 이를 피해야 한다고 제안합니다.

특히, 우리는 매우 인기 있는 UTF-16 인코딩(Windows 세계에서 종종 '와이드캐릭터' 또는 단순히 '유니코드'로 잘못 불림)이 특수 텍스트 처리 라이브러리(예: ICU)를 제외하고는 라이브러리 API에서 자리를 잡아서는 안 된다고 믿습니다.

또한 이 문서는 역사적인 이유와 API의 기본 UTF-8 지원 부재로 인해 Windows 애플리케이션 환경에서 덜 일반적임에도 불구하고, 내부 문자열 표현에 UTF-8 인코딩을 채택할 것을 권장합니다. 비록 해당 플랫폼(Windows)에서 네이티브 지원이 부족하더라도, 앞으로 서술할 근거가 그 단점을 상쇄할 만하다고 판단합니다. 또한, ‘ANSI 코드 페이지’가 무엇이고 어떤 용도로 사용되었는지 영원히 잊어버릴 것을 권고합니다. 사용자는 어떠한 텍스트 문자열에서도 원하는 수의 언어를 자유롭게 혼합하여 사용할 권리가 있습니다.

산업 전반에 걸쳐, 많은 지역화 관련 버그들이 프로그래머들의 유니코드 지식 부족으로 [비난](http://www.joelonsoftware.com/articles/Unicode.html)받아 왔습니다. 그러나 우리는 텍스트에 특화되지 않은 애플리케이션의 경우, 인프라가 프로그램이 인코딩 문제를 알지 못하도록 할 수 있고 그래야 한다고 믿습니다. 예를 들어, 파일 복사 유틸리티는 비영어 파일 이름을 지원하기 위해 다르게 작성될 필요가 없습니다. 이 선언문에서 우리는 또한 프로그래머가 유니코드의 모든 복잡성을 파고들지 않고 [문자열 내부](#cookie)에 대해 신경 쓰지 않으려면 무엇을 해야 하는지 설명할 것입니다.

더 나아가, 우리는 유니코드 코드 포인트를 세거나 반복하는 작업이 텍스트 처리 시나리오에서 특별히 중요한 작업으로 여겨져서는 안 된다고 제안하고 싶습니다. 많은 개발자들이 코드 포인트를 ASCII 문자의 일종의 후속 버전처럼 잘못 이해하고 있습니다. 이로 인해 파이썬의 문자열 O(1) 코드 포인트 접근과 같은 소프트웨어 설계 결정으로 이어졌습니다. 하지만 실제로 유니코드는 본질적으로 더 복잡하며, '유니코드 문자'라는 것에 대한 보편적인 정의가 없습니다. 우리는 유니코드 코드 포인트가 유니코드 그래핌 클러스터, 코드 유닛, 또는 심지어 언어의 단어보다 더 선호되어야 할 특별한 이유를 찾지 못했습니다. 반면, UTF-8 코드 유닛(바이트)을 텍스트의 기본 단위로 보는 것은 일반적으로 사용되는 텍스트 데이터 형식을 파싱하는 것과 같은 많은 작업에서 특히 유용합니다. 이는 이 인코딩의 특별한 기능 때문입니다. 그래핌, 코드 유닛, 코드 포인트 및 기타 관련 유니코드 용어는 [섹션 5](#characters)에서 설명됩니다. 인코딩된 텍스트 문자열에 대한 작업은 [섹션 7](#textops)에서 논의됩니다.

> 번역자 메모:    
> 일반적으로 16비트 크기의 문자 타입을 의미한다.    
> WinAPI(C/C++)애서는 문자열 처리를 위해 `wchar_t` 타입으로 구현됨.


[배경](#background)
-------------------------

1988년, Joseph D. Becker는 [첫 번째 유니코드 초안 제안](http://unicode.org/history/unicode88.pdf)을 발표했습니다. 그의 설계 기반은 한 문자당 16비트면 충분하다는 순진한 가정이었습니다. 1991년, 첫 번째 유니코드 표준이 발표되었으며, 코드 포인트는 16비트로 제한되었습니다. 이후 몇 년 동안 많은 시스템들이 유니코드를 지원하기 시작했고 UCS-2 인코딩으로 전환했습니다. 이는 특히 Qt 프레임워크(1992), Windows NT 3.1(1993), Java(1995)와 같은 새로운 기술에 매력적이었습니다.

그러나 곧 한 문자당 16비트로는 유니코드를 처리할 수 없다는 것이 밝혀졌습니다. 1996년, 기존 시스템이 16비트가 아닌 문자를 처리할 수 있도록 UTF-16 인코딩이 만들어졌습니다. 이는 고정 폭 인코딩이라는 초기 선택의 근거를 무효화했습니다. 현재 유니코드는 109,449개 이상의 문자를 포함하며, 그중 약 74,500개가 CJK 표의 문자입니다.

> 번역자 메모:    
> CJK는 중국어, 일본어, 한국어를 통틀어 표현하는 단어이다.   
> 이 글에서는 유니코드에 수록된 부호화용 '한자 집합'을 의미하는데, 이는 CJK Unified Ideographs라는 공식 명칭이 있다.

![인코딩에 대한 큰 포스터 앞에서 인코딩 게임을 하는 어린 아이.](https://utf8everywhere.org/data/nagoya-museum.jpg)
나고야 시립 과학관. Vadim Zlotnik 촬영.

Microsoft는 종종 '유니코드'와 '와이드캐릭터'를 'UCS-2'와 'UTF-16'의 동의어로 잘못 사용했습니다. 더 나아가, UTF-8을 좁은 문자열 WinAPI의 인코딩으로 설정할 수 없기 때문에, 코드를 `UNICODE` 정의와 함께 컴파일해야 합니다. Windows C++ 프로그래머들은 유니코드를 '와이드캐릭터'로 처리해야 한다고 교육받습니다(또는 더 나쁘게—컴파일러 설정에 의존하는 TCHAR를 사용하여 프로그래머가 모든 유니코드 코드 포인트를 지원하지 않도록 선택할 수 있습니다). 이 혼란의 결과로, 많은 Windows 프로그래머들은 텍스트에 대해 무엇이 올바른 것인지에 대해 상당히 혼란스러워하고 있습니다.

동시에, Linux와 웹 세계에서는 UTF-8이 유니코드를 위해 사용하기에 가장 좋은 인코딩이라는 암묵적인 합의가 있습니다. 영어와 컴퓨터 언어(예: C++, HTML, XML 등)에 대해 더 짧은 표현을 제공하므로 일반적으로 사용되는 문자 집합에 대해 UTF-16보다 효율적입니다.

[사실](#facts)
-------------------

*   UTF-8과 UTF-16 인코딩 모두에서 코드 포인트는 최대 4바이트까지 차지할 수 있습니다.
*   UTF-8은 엔디언 독립적입니다. UTF-16은 두 가지 버전이 있습니다: UTF-16LE와 UTF-16BE(각각 다른 바이트 순서). 여기서 우리는 이를 통칭하여 UTF-16이라고 부릅니다.
*   와이드캐릭터는 일부 플랫폼에서 2바이트, 다른 플랫폼에서 4바이트입니다.
*   UTF-8과 UTF-32는 사전식 순서로 정렬할 때 동일한 순서를 제공합니다. UTF-16은 그렇지 않습니다.
*   UTF-8은 영어 문자와 기타 ASCII 문자(한 문자당 1바이트)에 대해 효율성을 선호하는 반면, UTF-16은 몇몇 아시아 문자 집합(UTF-8에서 3바이트 대신 2바이트)에 대해 효율성을 선호합니다. 이는 영어 HTML/XML 태그가 모든 언어의 텍스트와 혼합되는 웹 세계에서 UTF-8이 선호되는 선택이 되었습니다. 키릴 문자, 히브리어 및 기타 인기 있는 유니코드 블록은 UTF-16과 UTF-8 모두에서 2바이트입니다.
*   UTF-16은 종종 고정 폭 인코딩으로 오용되며, Windows 패키지 프로그램 자체도 이를 오용합니다: 일반 Windows 편집 컨트롤(Vista 이전)에서 UTF-16에서 4바이트를 차지하는 문자를 삭제하려면 백스페이스를 두 번 눌러야 합니다. Windows 7에서는 콘솔이 사용 중인 폰트에 관계없이 이러한 문자를 두 개의 잘못된 문자로 표시합니다.
*   많은 Windows용 타사 라이브러리들은 유니코드를 지원하지 않습니다: 그들은 좁은 문자열 매개변수를 받아 ANSI API에 전달합니다. 때로는 파일 이름에 대해서도 마찬가지입니다. 일반적으로 이 문제를 해결할 방법은 없습니다. 문자열이 여러 유니코드 블록의 문자를 포함하는 경우 어떤 ANSI 코드 페이지로도 완전히 표현할 수 없기 때문입니다. Windows 프로그래머들이 파일 이름에 대해 일반적으로 하는 일은 파일이 이미 존재하는 경우 8.3 경로를 얻어 이를 라이브러리에 전달하는 것입니다. 라이브러리가 존재하지 않는 파일을 생성해야 하는 경우에는 이 방법을 사용할 수 없습니다. 경로가 매우 길고 8.3 형식이 `MAX_PATH`보다 길 경우에도 이 방법을 사용할 수 없습니다. OS 설정에서 짧은 이름 생성을 비활성화한 경우에도 이 방법을 사용할 수 없습니다.
*   C++에서는 `std::exception::what()`에서 유니코드를 반환하는 유일한 방법은 UTF-8을 사용하는 것입니다. `localeconv`에 대해 유니코드를 지원하는 유일한 방법은 UTF-8을 사용하는 것입니다.
*   UTF-16은 오늘날에도 Windows 세계 외부에서 인기가 있습니다. Qt, Java, C#, Python(CPython v3.3 참조 구현 이전, [아래 참조](#faq.python)) 및 [ICU](http://en.wikipedia.org/wiki/International_Components_for_Unicode)는 모두 내부 문자열 표현으로 UTF-16을 사용합니다.

> 번역가 메모:     
> UTF-16이 사전식 정렬이 불가능한 이유는 UCS-2와의 호환성을 지키기 위한 레거시 떄문이다.     
> UTF-16은 'BMP 바깥 범위를 표현하는 상태(서로게이트 페어 사용)'와 'BMP 범위를 표현하는 상태(UCS-2 인코딩 호환)'가 다르다.     
> 서로게이트 페어는 하나의 문자(코드 포인트)를 표현하기 위해 두 개의 16비트 단위(고위/저위 서로게이트)로 구성된다.      
> 이런 특징으로 인해서, UCS-2를 사용하거나 16비트 단위(코드 유닛)만을 독립적으로 비교하면 올바르지 않은 정렬 순서가 나올 수 있다.   

[불투명 데이터 주장](#cookie)
-------------------------------

파일 복사 유틸리티로 돌아가 봅시다. UNIX 세계에서는 좁은 문자열이 거의 모든 곳에서 기본적으로 UTF-8로 간주됩니다. 따라서 파일 복사 유틸리티의 작성자는 유니코드에 대해 신경 쓸 필요가 없습니다. 파일 이름 인수에 대해 ASCII 문자열로 테스트한 후, 인수가 [쿠키](http://en.wikipedia.org/wiki/Opaque_data_type)로 처리되므로 모든 언어의 파일 이름에 대해 올바르게 작동합니다. 파일 복사 유틸리티의 코드는 외국어를 지원하기 위해 전혀 변경할 필요가 없습니다. `fopen()`은 유니코드를 원활하게 받아들이며, `argv`도 마찬가지입니다.

이제 UTF-16 기반 아키텍처인 Microsoft Windows에서 이를 수행하는 방법을 살펴보겠습니다. 여러 다른 유니코드 블록(언어)의 파일 이름을 혼합하여 받아들일 수 있는 파일 복사 유틸리티를 만들려면 고급 트릭이 필요합니다. 먼저, 애플리케이션은 유니코드를 인식하도록 컴파일되어야 합니다. 이 경우, 표준-C 매개변수를 가진 `main()` 함수를 가질 수 없습니다. 그런 다음 UTF-16으로 인코딩된 `argv`를 받아들입니다. 좁은 텍스트를 염두에 두고 작성된 Windows 프로그램을 유니코드를 지원하도록 변환하려면 깊이 리팩토링하고 모든 문자열 변수를 처리해야 합니다.

MSVC와 함께 제공되는 표준 라이브러리는 유니코드 지원 측면에서 잘 구현되지 않았습니다. 좁은 문자열 매개변수를 OS ANSI API로 직접 전달합니다. 이를 재정의할 방법은 없습니다. `std::locale`을 변경해도 작동하지 않습니다. MSVC에서 표준 C++ 기능을 사용하여 유니코드 이름의 파일을 열 수 없습니다. 파일을 여는 표준 방법은 다음과 같습니다:

```cpp
std::fstream fout("abc.txt");
```

이 문제를 해결하는 올바른 방법은 Microsoft의 비표준 확장인 와이드 문자열 매개변수를 받아들이는 해킹을 사용하는 것입니다.

Windows에서는 `HKLM\SYSTEM\CurrentControlSet\Control\Nls\CodePage\ACP` 레지스트리 키를 통해 비ASCII 문자를 받을 수 있지만, 단일 ANSI 코드 페이지에서만 가능합니다. 65001의 구현되지 않은 값은 아마도 Windows에서 쿠키 문제를 해결할 것입니다. Microsoft가 이 ACP 값을 지원하도록 구현한다면, 이는 Windows 플랫폼에서 UTF-8의 더 넓은 채택에 도움이 될 것입니다.

Windows 프로그래머와 멀티플랫폼 라이브러리 공급업체를 위해, 우리는 텍스트 문자열 처리와 더 나은 유니코드 지원을 위한 프로그램 리팩토링에 대한 접근 방식을 [Windows에서 텍스트 처리 방법](#windows) 섹션에서 더 논의합니다.

[글리프, 그래핌 및 기타 유니코드 종류](#characters)
----------------------------------------------------------

다음은 유니코드 표준에 따른 문자, 코드 포인트, 코드 유닛 및 그래핌 클러스터에 대한 정의의 발췌문입니다. 더 자세한 설명을 위해 해당 표준의 관련 섹션을 참조하는 것이 좋습니다.

> Приве́т नमस्ते שָׁלוֹם 
> 몇 개의 _문자_ 가 보이나요?

*   **코드 포인트** — 유니코드 코드 공간의 모든 숫자 값.\[§3.4, D10\] 예: U+3243F.
    
*   **코드 유닛** — 인코딩된 텍스트의 단위를 나타낼 수 있는 최소 비트 조합.\[§3.9, D77\] 예를 들어, UTF-8, UTF-16 및 UTF-32는 각각 8비트, 16비트 및 32비트 코드 유닛을 사용합니다. 위의 코드 포인트는 UTF-8에서 '`f0 b2 90 bf`', UTF-16에서 '`d889 dc3f`', UTF-32에서 '`0003243f`'로 인코딩됩니다. 이들은 단지 _비트 그룹_ 의 시퀀스일 뿐이며, 이를 옥텟 지향 미디어에 저장하는 방법은 특정 인코딩의 엔디언에 따라 다릅니다. 위의 UTF-16 코드 유닛을 저장할 때, UTF-16BE에서는 '`d8 89 dc 3f`', UTF-16LE에서는 '`89 d8 3f dc`'로 변환됩니다.
    
*   **추상 문자** — 텍스트 데이터의 조직, 제어 또는 표현에 사용되는 정보 단위.\[§3.4, D7\] 표준은 §3.1에서 다음과 같이 말합니다:
    
    > 유니코드 표준의 경우, \[...\] 레퍼토리는 본질적으로 열려 있습니다. 유니코드는 보편적인 인코딩이므로, 인코딩될 수 있는 모든 추상 문자는 현재 알려져 있는지 여부에 관계없이 인코딩될 수 있는 잠재적인 후보입니다.
    
    이 정의는 실제로 추상적입니다. 어떤 것이 문자라고 생각할 수 있는 모든 것이 추상 문자입니다. 예를 들어, ![](data/glyph-ungwe.png) _텡과 문자 웅게_ 는 추상 문자이지만, 아직 유니코드에서 표현할 수 없습니다.
    
*   **인코딩된 문자**, **코드화된 문자** — 코드 포인트와 추상 문자 간의 매핑.\[§3.4, D11\] 예를 들어, U+1F428은 추상 문자 🐨 코알라를 나타내는 코드화된 문자입니다.
    
    이 매핑은 전체적이지도, 단사적이지도, 전사적이지도 않습니다:
    
    *   서로게이트, 비문자 및 할당되지 않은 코드 포인트는 추상 문자에 전혀 대응하지 않습니다.
    *   일부 추상 문자는 다른 코드 포인트로 인코딩될 수 있습니다; U+03A9 그리스 대문자 오메가와 U+2126 옴 기호는 모두 동일한 추상 문자 'Ω'에 대응하며, _동일하게 처리되어야 합니다_.
    *   일부 추상 문자는 단일 코드 포인트로 인코딩될 수 없습니다. 이들은 _시퀀스_ 의 코드화된 문자로 표현됩니다. 예를 들어, 추상 문자 ю́ _키릴 소문자 유에 악센트_ 를 표현하는 유일한 방법은 U+044E 키릴 소문자 유 다음에 U+0301 결합 악센트를 사용하는 것입니다.
    
    또한, 일부 추상 문자는 단일 코드화된 문자 형태 외에도 여러 코드 포인트를 사용하여 표현될 수 있습니다. 추상 문자 ǵ는 단일 코드 포인트 U+01F5 라틴 소문자 g에 악센트 또는 시퀀스 <U+0067 라틴 소문자 g, U+0301 결합 악센트\>로 코드화될 수 있습니다.
    
*   **사용자 인식 문자** — 최종 사용자가 문자라고 생각하는 것. 이 개념은 언어에 따라 다릅니다. 예를 들어, 'ch'는 영어와 라틴어에서는 두 글자이지만, 체코어와 슬로바키아어에서는 한 글자로 간주됩니다.
    
*   **그래핌 클러스터** — '함께 유지되어야 하는' 코드화된 문자의 시퀀스.\[§2.11\] 그래핌 클러스터는 언어 독립적인 방식으로 사용자 인식 문자의 개념을 근사화합니다. 이들은 커서 이동 및 선택과 같은 작업에 사용됩니다.
    
*   **글리프** — 폰트 내의 특정 모양. 폰트는 타이프 디자이너가 디자인한 글리프의 모음입니다. 텍스트 셰이핑 및 렌더링 엔진의 책임은 지정된 폰트 내에서 코드 포인트 시퀀스를 글리프 시퀀스로 변환하는 것입니다. 이 변환 규칙은 복잡할 수 있으며, 로케일에 의존적이며, 유니코드 표준의 범위를 벗어납니다.
    

'문자'는 위의 어떤 것을 가리킬 수 있습니다. 유니코드 표준은 이를 _코드화된 문자_ 의 동의어로 사용합니다.\[§3.4\] 프로그래밍 언어 또는 라이브러리 문서에서 '문자'라고 말할 때, 일반적으로 코드 유닛을 의미합니다. 최종 사용자에게 문자열의 문자 수를 물어보면, 그는 사용자 인식 문자를 셀 것입니다. 프로그래머는 코드 유닛, 코드 포인트 또는 그래핌 클러스터로 문자를 셀 수 있으며, 이는 프로그래머의 유니코드 전문 지식 수준에 따라 다릅니다. 예를 들어, [트위터는 이렇게 문자를 셉니다](https://developer.twitter.com/en/docs/basics/counting-characters.html). 우리의 의견으로는, 문자열 길이 함수가 문자열 '🐨'에 대해 1을 반환할 필요는 없습니다.

[아시아 텍스트: UTF-8 대 UTF-16](#asian)
---------------------------------------

대부분의 유니코드 코드 포인트는 UTF-8과 UTF-16에서 동일한 바이트 수를 차지합니다. 이는 러시아어, 히브리어, 그리스어 및 모든 비BMP 코드 포인트가 두 인코딩에서 2 또는 4바이트를 차지합니다. 라틴 문자와 구두점 및 기타 ASCII 문자는 UTF-16에서 더 많은 공간을 차지하는 반면, 일부 아시아 문자는 UTF-8에서 더 많은 공간을 차지합니다. 아시아 프로그래머들이 이론적으로 UTF-16을 버리는 데 반대할 수 있을까요? UTF-16은 문자당 메모리를 50% 절약합니다.

현실은 이렇습니다. 메모리를 절약하는 것은 U+0800에서 U+FFFF 범위의 문자만 포함하는 인위적으로 구성된 예제에서만 사실입니다. 그러나 컴퓨터 간 텍스트 인터페이스는 다른 모든 텍스트 사용을 지배합니다. 이는 XML, HTTP, 파일 시스템 경로 및 구성 파일을 포함하며, 이들은 거의 독점적으로 ASCII 문자를 사용하며, 실제로 UTF-8은 해당 아시아 국가에서 매우 인기가 있습니다.

중국어 책 전용 저장소로 UTF-16이 여전히 공정한 최적화로 사용될 수 있습니다. 그러나 텍스트가 이러한 저장소에서 검색되면 세계의 나머지 부분과 호환되는 표준으로 변환되어야 합니다. 어느 경우든, 저장 공간이 중요한 경우 무손실 압축이 사용될 것입니다. 이러한 경우, UTF-8과 UTF-16은 거의 동일한 공간을 차지할 것입니다. 더 나아가, '해당 언어에서 글리프는 \[라틴\] 문자보다 더 많은 정보를 전달하므로 더 많은 공간을 차지하는 것이 정당화됩니다.' (Tronic, [UTF-16은 해롭다고 간주됨](http://programmers.stackexchange.com/a/102211/34925)).

다음은 간단한 실험 결과입니다. 일부 웹 페이지(_일본_ 기사, 2012–01–01에 일본어 위키백에서 검색)의 HTML 소스가 사용하는 공간이 첫 번째 열에 표시됩니다. 두 번째 열은 마크업이 제거된 텍스트, 즉 '모두 선택, 복사, 일반 텍스트 파일에 붙여넣기' 결과를 보여줍니다.

|              | HTML Source (Δ UTF-8) | Dense text (Δ UTF-8) |
|--------------|-----------------------|----------------------|
| UTF-8        | 767 KB (0%)           | 222 KB (0%)          |
| UTF-16       | 1186 KB (+55%)         | 176 KB (-21%)         |
| UTF-8 zipped | 179 KB (-77%)          | 83 KB (-63%)          |
| UTF-16LE zipped| 192 KB (-75%)          | 76 KB (-66%)          |
| UTF-16BE zipped| 194 KB (-75%)          | 77 KB (-65%)          |


보시다시피, UTF-16은 실제 데이터에서 UTF-8보다 약 50% 더 많은 공간을 차지하며, 밀집 아시아 텍스트에 대해서는 20%만 절약하며, 일반 목적 압축 알고리즘과 거의 경쟁하지 못합니다. 이 선언문의 [중국어 번역](zh-cn)은 UTF-16에서 58.8 KiB, UTF-8에서 51.7 KiB를 차지합니다.

[인코딩된 문자열에 대한 텍스트 작업](#textops)
----------------------------------------------

인기 있는 텍스트 기반 데이터 형식(예: CSV, XML, HTML, JSON, RTF 및 컴퓨터 프로그램의 소스 코드)은 종종 구조 제어 요소로 ASCII 문자를 포함하며 ASCII 및 비ASCII 텍스트 데이터 문자열을 모두 포함할 수 있습니다. ASCII 상속 코드 포인트가 다른 코드 포인트보다 짧은 가변 길이 인코딩으로 작업하는 것은 문자열 내에서 인코딩된 문자 경계가 즉시 알려지지 않기 때문에 어려운 작업처럼 보일 수 있습니다. 이로 인해 소프트웨어 설계자들은 UCS-4 고정 폭 인코딩을 선택하게 되었습니다(예: [Python v3.3](#faq.python)). 사실, 이는 불필요하며 우리가 알고 있는 실제 문제를 해결하지 못합니다.

이 인코딩의 설계에 따라, UTF-8은 ASCII 문자 값 또는 부분 문자열이 다중 바이트 인코딩된 문자의 일부와 일치하지 않음을 보장합니다. UTF-16도 마찬가지입니다. 두 인코딩 모두에서 다중 부분 인코딩된 코드 포인트의 코드 유닛은 MSB가 1로 설정됩니다.

예를 들어, HTML 태그의 시작을 표시하는 '<' 기호 또는 SQL 문에서 SQL 인젝션을 방어하기 위한 아포스트로피(')를 찾으려면, 모든 영어 평문 ASCII 문자열에 대해 수행하는 것처럼 수행하십시오. 인코딩은 이 작업이 작동하도록 보장합니다. 특히, 모든 비ASCII 문자는 UTF-8에서 값이 127보다 큰 바이트 시퀀스로 인코딩됩니다. 이는 단순하고 빠르며 우아한 알고리즘을 위해 충돌할 여지를 남기지 않으며, 인코딩된 문자 경계에 대해 신경 쓸 필요가 없습니다.

또한, UTF-8로 인코딩된 비ASCII 부분 문자열을 UTF-8 문자열에서 평문 바이트 배열처럼 검색할 수 있습니다—코드 포인트 경계를 신경 쓸 필요가 없습니다. 이는 UTF-8의 또 다른 설계 기능 덕분입니다—인코딩된 코드 포인트의 선행 바이트는 다른 코드 포인트의 후행 바이트 중 하나에 해당하는 값을 가질 수 없습니다.

[문자 수 계산에 대한 추가 오해](#myths)
----------------------------------------------

이미 언급했듯이, 유니코드 문자열에서 코드 포인트를 세거나, 분할하거나, 인덱싱하거나 반복하는 것이 빈번하고 중요한 작업으로 간주되어야 한다는 인기가 있습니다. 이 섹션에서 우리는 이를 더 자세히 검토합니다.

### [UTF-16으로 문자 수를 상수 시간에 계산할 수 있습니다.](#myth.utf16.o1)

이는 UTF-16이 고정 폭 인코딩이라고 생각하는 사람들의 일반적인 실수입니다. 사실 UTF-16은 가변 길이 인코딩입니다. 비BMP 문자의 존재를 부인한다면 [이 FAQ](#faq.almostfw)를 참조하십시오.

### [UTF-32로 문자 수를 상수 시간에 계산할 수 있습니다.](#myth.utf32.o1)

이는 잘못 사용된 '문자'라는 단어의 의미에 따라 다릅니다. UTF-32에서 코드 유닛과 코드 포인트를 상수 시간에 셀 수 있다는 것은 사실입니다. 그러나 코드 포인트는 사용자 인식 문자에 대응하지 않습니다. 유니코드 형식주의에서도 일부 코드 포인트는 _코드화된 문자_에 대응하고 일부는 _비문자_에 대응합니다.

### [코드화된 문자 또는 코드 포인트를 세는 것이 중요합니다.](#myth.strlen)

우리는 코드 포인트의 중요성이 종종 과대 평가된다고 생각합니다. 이는 인간 언어의 복잡성을 반영하는 유니코드의 복잡성에 대한 일반적인 오해 때문입니다. 'Abracadabra'에 몇 개의 문자가 있는지 말하기는 쉽지만, 다음 문자열로 돌아가 봅시다:

Приве́т नमस्ते שָׁלוֹם

이 문자열은 22개의 코드 포인트로 구성되지만, 16개의 그래핌 클러스터만 있습니다. [NFC](http://unicode.org/reports/tr15/)로 변환하면 20개의 코드 포인트로 줄어들 수 있습니다. 그러나 이 문자열의 코드 포인트 수는 거의 모든 소프트웨어 엔지니어링 작업과 무관하며, 아마도 문자열을 UTF-32로 변환하는 경우를 제외하고는 그렇습니다. 예를 들어:

*   커서 이동, 텍스트 선택 및 유사한 작업에는 _그래핌 클러스터_ 가 사용되어야 합니다.
*   입력 필드, 파일 형식, 프로토콜 또는 데이터베이스에서 문자열의 길이를 제한하는 경우, 길이는 미리 결정된 인코딩의 _코드 유닛_ 으로 측정됩니다. 이유는 모든 길이 제한은 메모리, 디스크 또는 특정 데이터 구조에서 문자열에 할당된 고정된 양의 메모리에서 파생되기 때문입니다.
*   화면에 나타나는 문자열의 크기는 문자열의 코드 포인트 수와 관련이 없습니다. 이를 위해 렌더링 엔진과 통신해야 합니다. 코드 포인트는 모노스페이스 폰트와 터미널에서도 한 열을 차지하지 않습니다. POSIX는 이를 고려합니다.

### [NFC에서 각 코드 포인트는 하나의 사용자 인식 문자에 대응합니다.](#myth.nfc)

아니요, 유니코드에서 표현할 수 있는 사용자 인식 문자의 수는 사실상 무한하기 때문입니다. 실제로도 대부분의 문자는 완전히 구성된 형태를 가지고 있지 않습니다. 예를 들어, 위 예제의 NFD 문자열은 세 _실제_ 언어의 세 _실제_ 단어로 구성되며, NFC에서는 20개의 코드 포인트로 구성됩니다. 이는 여전히 16개의 사용자 인식 문자보다 훨씬 많습니다.

### [문자열 `length()` 작업은 사용자 인식 또는 코드화된 문자를 세야 합니다. 그렇지 않으면 유니코드를 제대로 지원하지 않습니다.](#myth.strlen.correctness)

라이브러리와 프로그래밍 언어의 유니코드 지원은 종종 '문자열 길이' 작업에 대해 반환된 값으로 평가됩니다. 이 유니코드 지원 평가에 따르면, C#, Java 및 심지어 ICU 자체와 같은 대부분의 인기 있는 언어는 유니코드를 지원하지 않습니다. 예를 들어, 한 문자 문자열 '🐨'의 길이는 UTF-16이 내부 문자열 표현으로 사용되는 경우 2로 보고되고, UTF-8을 내부적으로 사용하는 언어의 경우 4로 보고될 것입니다. 이 오해의 근원은 이러한 언어의 사양이 '문자'라는 단어를 코드 유닛을 의미하는 것으로 사용하는 반면, 프로그래머는 다른 것을 기대한다는 것입니다.

그러나 이러한 API에서 반환된 코드 유닛 수는 실제로 가장 높은 실질적인 중요성을 가집니다. UTF-8 문자열을 파일에 쓸 때, 바이트 단위의 길이가 중요합니다. 반면, 다른 유형의 '문자'를 세는 것은 그다지 도움이 되지 않습니다.

[우리의 결론](#conclusions)
-------------------------------

UTF-16은 가변 길이이면서 너무 넓은 최악의 조합입니다. 이는 역사적인 이유로만 존재하며 많은 혼란을 일으킵니다. 우리는 그 사용이 더 줄어들기를 바랍니다.

이식성, 크로스 플랫폼 상호 운용성 및 단순성은 기존 플랫폼 API와의 상호 운용성보다 더 중요합니다. 따라서 최선의 접근 방식은 모든 곳에서 UTF-8 좁은 문자열을 사용하고, UTF-8을 지원하지 않고 와이드 문자열을 받아들이는 플랫폼 API(예: Windows API)를 사용할 때 이를 앞뒤로 변환하는 것입니다. [성능은 문자열을 받아들이는 시스템 API(예: UI 코드 및 파일 시스템 API)를 다룰 때 거의 문제가 되지 않으며](#faq.cvt.perf), 애플리케이션의 다른 모든 곳에서 동일한 인코딩을 사용하는 데 큰 이점이 있으므로, [우리는 다른 방법을 사용할 충분한 이유를 찾지 못했습니다](#faq.liberal).

성능에 대해 말하자면, 기계는 종종 문자열을 사용하여 통신합니다(예: HTTP 헤더, XML, SOAP). 많은 사람들이 이를 자체적으로 실수로 보지만, 그것과 관계없이 이는 거의 항상 영어와 ASCII로 수행되며, 이는 UTF-8에 추가적인 이점을 제공합니다. 다른 종류의 문자열에 대해 다른 인코딩을 사용하면 복잡성과 결과적인 버그가 크게 증가합니다.

특히, 우리는 C++ 표준에 `wchar_t`를 추가한 것이 실수라고 믿으며, C++11의 유니코드 추가도 마찬가지입니다. 그러나 구현에서 요구되어야 하는 것은 _기본 실행 문자 집합_ 이 모든 유니코드 데이터를 저장할 수 있어야 한다는 것입니다. 그러면 모든 `std::string` 또는 `char*` 매개변수가 유니코드와 호환될 것입니다. '이것이 텍스트를 받아들이면, 유니코드와 호환되어야 합니다'—그리고 UTF-8을 사용하면 이를 쉽게 달성할 수 있습니다.

[표준 패싯에는 많은 설계 결함이 있습니다](http://www.boost.org/doc/libs/1_58_0/libs/locale/doc/html/rationale.html). 이는 `std::numpunct`, `std::moneypunct` 및 `std::ctype`이 가변 길이 인코딩된 문자(비ASCII UTF-8 및 비BMP UTF-16)를 지원하지 않거나 변환을 수행할 정보를 가지고 있지 않다는 것을 포함합니다. 이들은 수정되어야 합니다:

*   `decimal_point()` 및 `thousands_sep()`는 단일 코드 유닛이 아닌 문자열을 반환해야 합니다. 이는 C 로케일이 `localeconv` 함수를 통해 이를 수행하는 방식이지만, 사용자 정의할 수 없습니다.
*   `toupper()` 및 `tolower()`는 코드 유닛 단위로 표현되어서는 안 됩니다. 이는 유니코드에서 작동하지 않습니다. 예를 들어, 라틴 ﬄ 합자는 FFL로 변환되어야 하며, 독일어 ß는 SS로 변환되어야 합니다(대문자 형태 ẞ가 있지만, 대소문자 규칙은 전통적인 것을 따릅니다). 또한, 일부 언어(예: 그리스어)는 일부 소문자의 특수한 최종 형태를 가지고 있으므로, 대소문자 변환 루틴은 이를 올바르게 수행하기 위해 위치를 인식해야 합니다.

[Windows에서 텍스트 처리 방법](#windows)
-------------------------------------

이 섹션은 멀티플랫폼 라이브러리 개발 및 Windows 프로그래밍에 전념합니다. Windows 플랫폼의 문제는 (아직) 유니코드와 호환되는 좁은 문자열 시스템 API를 지원하지 않는다는 것입니다. Windows API에 유니코드 문자열을 전달하는 유일한 방법은 UTF-16(와이드 문자열)로 변환하는 것입니다.

우리의 지침은 Microsoft의 원래 유니코드 변환 가이드와 크게 다릅니다. 우리의 접근 방식은 API 호출에 가능한 한 가까운 곳에서 와이드 문자열 변환을 수행하고, 와이드 문자열 데이터를 절대 보유하지 않는 것입니다. 이전 섹션에서 우리는 이 방법이 일반적으로 더 나은 성능, 안정성, 코드 단순성 및 다른 소프트웨어와의 상호 운용성을 제공한다고 설명했습니다.

*   UTF-16을 받아들이는 API에 인접한 곳 이외의 어떤 곳에서도 `wchar_t` 또는 `std::wstring`을 사용하지 마십시오.
*   UTF-16을 받아들이는 API에 매개변수로 사용하는 곳 이외의 어떤 곳에서도 `_T("")` 또는 `L""` 리터럴을 사용하지 마십시오.
*   `UNICODE` 상수에 민감한 타입, 함수 또는 그 파생물(예: `LPTSTR`, `CreateWindow()` 또는 `_T()` 매크로)을 사용하지 마십시오. 대신, `LPWSTR`, `CreateWindowW()` 및 명시적 `L""` 리터럴을 사용하십시오.
*   그러나 `UNICODE` 및 `_UNICODE`는 항상 정의되어, 좁은 UTF-8 문자열이 ANSI WinAPI에 조용히 컴파일되는 것을 방지합니다. 이는 VS 프로젝트 설정에서 **유니코드 문자 집합 사용**으로 자동으로 수행됩니다.
*   `std::string` 및 `char*` 변수는 프로그램 어디에서나 UTF-8로 간주됩니다.
*   C++로 작성할 수 있는 권한이 있다면, 아래의 `narrow()`/`widen()` 변환 함수를 인라인 변환 구문에 유용하게 사용할 수 있습니다. 물론, 다른 UTF-8/UTF-16 변환 코드도 사용할 수 있습니다.
*   와이드캐릭터(`LPWSTR`)를 받아들이는 Win32 함수만 사용하고, `LPTSTR` 또는 `LPSTR`을 받아들이는 함수는 절대 사용하지 마십시오. 매개변수를 다음과 같이 전달하십시오:
    
    ```cpp
    ::SetWindowTextW(widen(someStdString or "string litteral").c_str())
    ```
    
    이 정책은 아래 설명된 변환 함수를 사용합니다. 또한, [변환 성능에 대한 참고](#faq.cvt.perf)를 참조하십시오.
    
*   MFC 문자열 사용 시:
    
    ```cpp
    CString someoneElse; // MFC에서 도착한 것.
    
    // 가능한 한 빨리 변환하여 API 호출에서 더 멀리 전달하기 전에:
    std::string s = str(boost::format("Hello %s\n") % narrow(someoneElse));
    AfxMessageBox(widen(s).c_str(), L"Error", MB_OK);
    ```
    
*   .NET 개발자: 네이티브 UTF-16 기반 문자열 클래스를 사용하는 것을 피하기 어려울 수 있습니다. 이 구현 세부 사항은 이 클래스의 인터페이스를 통해 많이 누출된다는 것을 기억하십시오. 예를 들어, `string[index]` 작업은 문자의 일부를 반환할 수 있습니다(UTF-8 바이트 배열과 마찬가지로). 문자열을 출력 파일이나 통신 장치에 직렬화할 때, `Encoding.UTF8`을 지정하는 것을 기억하십시오. ASP.NET 웹 애플리케이션과 같이 일반적으로 UTF-8 HTML 출력을 생성하는 경우 변환에 대한 성능 패널티를 지불할 준비를 하십시오.

### [Windows에서 파일, 파일 이름 및 fstream 작업](#how.files)

*   항상 텍스트 출력 파일을 UTF-8로 생성하십시오.
*   `fopen()` 사용은 [RAII/OOD](http://en.wikipedia.org/wiki/RAII) 이유로 피해야 합니다. 그러나 필요한 경우, `_wfopen()` 및 위에서 설명한 WinAPI 규칙을 사용하십시오.
*   `std::string` 또는 `const char*` 파일 이름 인수를 `fstream` 계열에 전달하지 마십시오. MSVC CRT는 UTF-8 인수를 지원하지 않지만, 다음과 같이 사용해야 하는 비표준 확장이 있습니다:
*   `std::string` 인수를 `widen`을 사용하여 `std::wstring`으로 변환하십시오:
    
    ```cpp
    std::ifstream ifs(widen("hello"), std::ios_base::binary);
    ```
    
    MSVC의 `fstream`에 대한 태도가 변경되면 수동으로 변환을 제거해야 합니다.
    
*   이 코드는 멀티플랫폼이 아니며 미래에 수동으로 변경해야 할 수 있습니다.
*   또는 변환을 숨기는 래퍼 세트를 사용하십시오.

### [변환 함수](#how.cvt)

이 지침은 [Boost.Nowide 라이브러리](http://cppcms.com/files/nowide/html/)의 변환 함수를 사용합니다(아직 boost의 일부가 아님):

```cpp
std::string narrow(const wchar_t *s);
std::wstring widen(const char *s);
std::string narrow(const std::wstring &s);
std::wstring widen(const std::string &s);
```

이 라이브러리는 파일을 다루는 표준 C 및 C++ 라이브러리 함수에 대한 래퍼 세트와 iostream을 통해 UTF-8을 읽고 쓰는 수단도 제공합니다.

이 함수와 래퍼는 Windows의 `MultiByteToWideChar` 및 `WideCharToMultiByte` 함수를 사용하여 쉽게 구현할 수 있습니다. 다른 (아마도 더 빠른) 변환 루틴을 사용할 수도 있습니다.

[FAQ](#faq)
-----------

### [Q: 당신은 리눅서인가요? 이건 Windows에 대한 은밀한 종교적 싸움인가요?](#faq.linuxer)

A: 아니요, 저는 Windows에서 자랐고, 주로 Windows 개발자입니다. 저는 Microsoft가 텍스트 도메인에서 잘못된 설계 선택을 했다고 믿습니다. 왜냐하면 그들은 다른 사람들보다 먼저 했기 때문입니다.

### [Q: 당신은 앵글로필인가요? 영어 알파벳과 문화가 다른 어떤 것보다 우월하다고 은밀히 생각하나요?](#faq.anglophile)

A: 아니요, 제 국가는 비ASCII 언어를 사용합니다. 저는 ASCII 문자를 단일 바이트로 인코딩하는 형식을 사용하는 것이 앵글로 중심주의라고 생각하지 않으며, 인간 상호 작용과 관련이 있다고 생각하지 않습니다. 프로그램의 소스 코드, 웹 페이지 및 XML 파일, OS 파일 이름 및 기타 컴퓨터 간 텍스트 인터페이스가 존재해서는 안 된다고 주장할 수 있지만, 그것들이 존재하는 한, 텍스트는 항상 인간 관객을 위해 구성되는 것은 아닙니다.

### [Q: 왜 신경 쓰나요? 저는 C# 및/또는 Java로 프로그래밍하고 인코딩에 대해 신경 쓸 필요가 없습니다.](#faq.why.care)

A: 이는 거짓입니다. C#과 Java 모두 16비트 `char` 타입을 제공하며, 이는 유니코드 문자보다 작습니다. .NET 인덱서 `str[i]`는 내부 표현 단위로 작동하므로, 다시 한 번 누출된 추상화입니다. 부분 문자열 메서드는 비BMP 문자를 부분적으로 잘라내어 잘못된 문자열을 반환할 수 있습니다.

또한, 텍스트를 디스크 파일, 네트워크 통신, 외부 장치 또는 다른 프로그램이 읽을 수 있는 곳에 쓸 때 인코딩을 신경 써야 합니다. `System.Text.Encoding.UTF8`(.NET)을 사용하십시오. `Encoding.ASCII`, UTF-16 또는 휴대폰 PDU를 사용하지 마십시오. 내용에 대한 가정에 관계없이.

ASP.NET과 같은 웹 프레임워크는 기본 프레임워크의 내부 문자열 표현의 잘못된 선택으로 인해 고통받습니다: 웹 애플리케이션의 예상 문자열 출력(및 입력)은 거의 항상 UTF-8이며, 이는 높은 처리량의 웹 애플리케이션 및 웹 서비스에서 상당한 변환 오버헤드를 초래합니다.

### [Q: UTF-8은 단순히 ASCII와 호환되려는 시도가 아닌가요? 왜 이 오래된 화석을 유지하나요?](#faq.utf8.fossil)

A: UTF-8이 원래 호환성 해킹으로 만들어졌는지 여부와 관계없이, 오늘날 그것은 다른 어떤 인코딩보다 더 나은 인기 있는 유니코드 인코딩입니다.

### [Q: UTF-16에서 두 바이트 이상을 차지하는 문자는 실제 세계에서 극히 드뭅니다. 이는 UTF-16을 사실상 고정 폭 인코딩으로 만들어 많은 이점을 제공합니다. 이 문자들을 무시할 수 없나요?](#faq.almostfw)

A: 소프트웨어 설계에서 모든 유니코드를 지원하지 않겠다는 것에 대해 진지한가요? 그리고 어쨌든 지원할 것이라면, 비BMP 문자가 드물다는 사실이 실제로 무엇을 바꾸나요, 소프트웨어 테스트를 더 어렵게 만드는 것 외에? 그러나 중요한 것은 텍스트 조작이 실제 애플리케이션에서 상대적으로 드물다는 것입니다—문자열을 그대로 전달하는 것에 비해. 이는 "거의 고정 폭"이 성능상의 이점이 거의 없음을 의미하며, 더 짧은 문자열이 중요할 수 있습니다.

### [Q: 왜 프로그래머가 자신이 좋아하는 인코딩을 내부적으로 사용하도록 허용하지 않나요?](#faq.liberal)

A: 우리는 어떤 인코딩의 올바른 사용에 반대하지 않습니다. 그러나 `std::string`과 같은 동일한 타입이 다른 컨텍스트에서 다른 의미를 가질 때 문제가 됩니다. 어떤 사람들에게는 'ANSI 코드 페이지'를 의미하고, 다른 사람들에게는 '이 코드는 깨져 있고 비영어 텍스트를 지원하지 않음'을 의미합니다. 우리 프로그램에서는 유니코드를 인식하는 UTF-8 문자열을 의미합니다. 이 다양성은 많은 버그와 불행의 원천입니다. 이 추가적인 복잡성은 세상이 실제로 필요로 하지 않는 것입니다. 결과는 유니코드가 깨진 소프트웨어가 산업 전반에 걸쳐 많이 생기는 것입니다. JoelOnSoftware는 [모든 프로그래머가 인코딩을 인식하도록 하는 것이 유니코드가 깨진 소프트웨어에 대한 해결책](http://www.joelonsoftware.com/articles/Unicode.html)이라고 제안합니다. 우리는 하나의 주류 인코딩이 소프트웨어 API의 기본이 되면, [텍스트 및 언어 문제에 대한 전문가가 되지 않고도 올바른 파일 복사 프로그램을 작성할 수 있다고](#cookie) 믿습니다.

### [Q: 내 애플리케이션은 GUI 전용입니다. IP 통신이나 파일 IO를 하지 않습니다. 왜 Windows API 호출을 위해 문자열을 앞뒤로 변환해야 하나요, 와이드 상태 변수를 사용하는 대신?](#faq.win.liberal)

이는 유효한 지름길입니다. 실제로, 와이드 문자열을 사용하는 것이 합법적인 경우일 수 있습니다. 그러나 미래에 구성 파일이나 로그 파일을 추가할 계획이라면, 전체를 좁은 문자열로 변환하는 것을 고려하십시오. 이는 미래에 대비하는 것입니다.

### [Q: 왜 `UNICODE` 정의를 켜나요, Windows의 `LPTSTR`/`TCHAR`/등 매크로를 사용할 의도가 없다면?](#faq.def.unicode)

A: 이는 UTF-8 `char*` 문자열을 ANSI를 기대하는 함수 변형에 연결하는 것을 방지하기 위한 추가 안전 메커니즘입니다. 우리는 컴파일러 오류를 발생시키기를 원합니다. 이는 Windows에서 `argv[]` 문자열을 `fopen()`에 전달하는 것과 같은 종류의 찾기 어려운 버그입니다: 사용자가 현재 코드 페이지가 아닌 파일 이름을 전달하지 않을 것이라고 가정합니다. 테스터가 중국어 파일 이름을 가끔 제공하도록 훈련되지 않는 한, 이 종류의 버그를 수동 테스트로 찾기 어려울 것입니다. `UNICODE` 정의 덕분에, 이에 대해 컴파일러 오류를 얻을 수 있습니다.

### [Q: Microsoft가 언젠가 와이드캐릭터 사용을 중단할 것이라고 생각하는 것은 꽤 순진한 생각이 아닌가요?](#faq.naive)

A: 먼저 `CP_UTF8`을 유효한 코드 페이지로 지원하기 시작할 때를 보겠습니다. 이는 매우 어려운 일이 아니어야 합니다. 그런 다음, 우리는 Windows 개발자가 와이드캐릭터 API를 계속 사용할 이유를 찾지 못합니다. 또한, `CP_UTF8` 지원을 추가하면 일부 기존 유니코드가 깨진 프로그램과 라이브러리를 '고칠' 수 있습니다.

일부는 `CP_UTF8` 지원이 ANSI API를 사용하는 기존 애플리케이션을 _깨뜨릴_ 것이라고 말하며, 이 때문에 Microsoft가 와이드 문자열 API를 만들어야 했다고 말합니다. 이는 사실이 아닙니다. 일부 인기 있는 ANSI 인코딩은 가변 길이(Shift JIS 등)이므로, 올바른 코드는 깨지지 않을 것입니다. Microsoft가 UCS-2를 선택한 이유는 순전히 역사적입니다. 당시 UTF-8은 아직 존재하지 않았고, 유니코드는 '단지 더 넓은 ASCII'로 여겨졌으며, 고정 폭 인코딩을 사용하는 것이 중요하다고 여겨졌습니다.

### [Q: 바이트 순서 표시(BOM)에 대해 어떻게 생각하나요?](#faq.boms)

A: 유니코드 표준(v6.2, p.30)에 따르면: UTF-8에 대해 BOM 사용은 필요하지도 권장되지도 않습니다.

바이트 순서 문제는 UTF-16을 피해야 하는 또 다른 이유입니다. UTF-8은 엔디언 문제가 없으며, UTF-8 BOM은 이 스트림이 UTF-8임을 나타내기 위해만 존재합니다. UTF-8이 유일한 인기 있는 인코딩으로 남는다면(이미 인터넷 세계에서는 그렇습니다), BOM은 불필요해집니다. 실제로, 대부분의 UTF-8 텍스트 파일은 오늘날 BOM을 생략합니다.

BOM을 사용하려면 모든 기존 코드가 이를 인식해야 하며, 파일 연결과 같은 간단한 시나리오에서도 마찬가지입니다. 이는 받아들일 수 없습니다.

### [Q: 줄 끝에 대해 어떻게 생각하나요?](#faq.crlf)

A: 항상 `\n (0x0a)` 줄 끝을 사용하십시오, Windows에서도 마찬가지입니다. 파일은 바이너리 모드로 읽고 써야 하며, 이는 상호 운용성을 보장합니다—프로그램은 모든 시스템에서 동일한 출력을 제공할 것입니다. C 및 C++ 표준이 메모리 내 줄 끝으로 `\n`을 사용하므로, 이는 모든 파일이 POSIX 규칙으로 작성되도록 할 것입니다. Windows에서 Notepad로 파일을 열 때 문제가 발생할 수 있지만, 어떤 괜찮은 텍스트 편집기도 이러한 줄 끝을 이해합니다.

우리는 또한 SI 단위, [ISO-8601](https://en.wikipedia.org/?title=ISO_8601) 날짜 형식 및 [부동 소수점](https://en.wikipedia.org/wiki/Decimal_mark#Countries_using_Arabic_numerals_with_decimal_comma)을 선호합니다.

### [Q: 텍스트 처리 알고리즘, 바이트 정렬 등의 성능은 어떻습니까?](#faq.uni.perf)

A: UTF-16이 더 나을까요? 아마도 그럴 것입니다. ICU는 역사적인 이유로 UTF-16을 사용하므로 측정하기가 상당히 어렵습니다. 그러나 대부분의 경우 문자열은 쿠키로 처리되며, 매초마다 정렬되거나 반전되지 않습니다. 더 밀집된 인코딩이 성능에 유리합니다.

### [Q: 사람들이 UTF-16을 16비트 문자라고 잘못 가정하는 것이 UTF-16의 잘못인가요?](#faq.utf16.fault)

A: 그렇지 않습니다. 그러나 안전성은 모든 설계의 중요한 기능이며, 인코딩도 예외는 아닙니다.

### [Q: `std::string`이 UTF-8을 의미한다면, `std::string`에 일반 텍스트를 저장하는 코드와 혼동되지 않을까요?](#faq.confuse)

A: 일반 텍스트라는 것은 없습니다. 코드 페이지-ANSI 또는 ASCII 전용 텍스트를 '문자열'이라는 클래스에 저장할 이유가 없습니다.

### [Q: Windows에 문자열을 전달할 때 UTF-8과 UTF-16 사이의 변환이 내 애플리케이션을 느리게 만들지 않을까요?](#faq.cvt.perf)

A: 먼저, 어떤 방식으로든 _어떤_ 변환을 할 것입니다. 시스템을 호출할 때나, 텍스트 문자열을 TCP로 보낼 때와 같이 세계의 나머지 부분과 상호 작용할 때입니다. 또한, 문자열을 받아들이는 OS API는 종종 UI 또는 파일 시스템 작업과 같이 본질적으로 느린 작업을 수행합니다. 시스템 API와의 상호 작용이 애플리케이션을 지배한다면, 여기 작은 실험이 있습니다.

OS API의 일반적인 사용 중 하나는 파일을 여는 것입니다. 이 함수는 내 머신에서 (184 ± 3)μs에 실행됩니다:

```cpp
void f(const wchar_t* name)
{
    HANDLE f = CreateFile(name, GENERIC_WRITE, FILE_SHARE_READ, 0, CREATE_ALWAYS, 0, 0);
    DWORD written;
    WriteFile(f, "Hello world!\n", 13, &written, 0);
    CloseHandle(f);
}
```

이 함수는 (186 ± 0.7)μs에 실행됩니다:

```cpp
void f(const char* name)
{
    HANDLE f = CreateFile(widen(name).c_str(), GENERIC_WRITE, FILE_SHARE_READ, 0, CREATE_ALWAYS, 0, 0);
    DWORD written;
    WriteFile(f, "Hello world!\n", 13, &written, 0);
    CloseHandle(f);
}
```

(두 경우 모두 `name="D:\\a\\test\\subdir\\subsubdir\\this is the sub dir\\a.txt"`로 실행. 5회 실행 평균. C++11에서 보장된 `std::string` 연속 저장소를 사용하는 최적화된 `widen`을 사용했습니다.)

이는 단지 (1 ± 2)% 오버헤드입니다. 또한, `MultiByteToWideChar`는 가장 빠른 UTF-8↔UTF-16 변환 함수가 아닙니다.

### [Q: C++ 코드에서 UTF-8 문자열 리터럴을 어떻게 작성하나요?](#faq.literal)

A: 소프트웨어를 국제화한다면 모든 비ASCII 문자열은 외부 번역 데이터베이스에서 로드될 것이므로 문제가 되지 않습니다.

여전히 특수 문자를 포함하고 싶다면 다음과 같이 할 수 있습니다. C++11에서는 다음과 같이 할 수 있습니다:

```cpp
u8"∃y ∀x ¬(x ≺ y)"
```

'u8'을 지원하지 않는 컴파일러에서는 다음과 같이 UTF-8 코드 유닛을 하드코딩할 수 있습니다:

```cpp
"\xE2\x88\x83y \xE2\x88\x80x \xC2\xAC(x \xE2\x89\xBA y)"
```

그러나 가장 간단한 방법은 문자열을 그대로 작성하고 소스 파일을 UTF-8로 저장하는 것입니다:

```cpp
"∃y ∀x ¬(x ≺ y)"
```

불행히도, MSVC는 이를 일부 ANSI 코드 페이지로 변환하여 문자열을 손상시킵니다. 이를 해결하려면 파일을 BOM 없이 UTF-8로 저장하십시오. MSVC는 이를 올바른 코드 페이지로 간주하고 문자열을 건드리지 않을 것입니다. 그러나 유니코드 식별자와 와이드 문자열 리터럴(어쨌든 사용하지 않을 것입니다)을 사용할 수 없게 됩니다.

### [Q: 복잡하고 큰 char 기반 Windows 애플리케이션이 있습니다. 이를 유니코드 인식으로 만드는 가장 쉬운 방법은 무엇인가요?](#faq.convert)

char를 유지하십시오. `UNICODE` 및 `_UNICODE`를 정의하여 `narrow()`/`widen()`을 사용해야 하는 곳에서 컴파일러 오류를 얻으십시오(이것은 Visual Studio 프로젝트 설정에서 **유니코드 문자 집합 사용**으로 자동으로 수행됩니다). 모든 `fstream` 및 `fopen()` 사용을 찾아 위에서 설명한 와이드 오버로드를 사용하십시오. 이제 거의 다 했습니다.

유니코드를 지원하지 않는 타사 라이브러리를 사용하는 경우(예: 파일 이름 문자열을 그대로 `fopen()`에 전달), 위에서 보여준 `GetShortPathName()`과 같은 도구로 해결해야 합니다.

### [Q: Python은 어떻습니까? v3.3에서 유니코드를 더 잘 지원하기 위해 열심히 노력했다고 들었습니다.](#faq.python)

A: 아마도, 그들이 덜 했더라면 지원이 더 나았을 것입니다. CPython v3.3 참조 구현에서 내부 문자열 표현이 변경되었습니다. UTF-16이 실제 문자열 내용에 따라 세 가지 가능한 인코딩(ISO-8859-1, UCS-2 또는 UCS-4) 중 하나로 대체되었습니다. 단일 비ASCII 또는 비BMP 문자를 추가하면 전체 문자열이 종종 다른 인코딩으로 암시적으로 변환됩니다. 내부 인코딩은 스크립트에 투명합니다. 이 설계는 유니코드 코드 포인트에 대한 인덱싱 작업의 성능을 _최적화_ 하기 위한 것입니다. 그러나 우리는 코드 포인트를 세거나 인덱싱하는 것이 대부분의 사용 사례에서 중요하지 않아야 한다고 주장합니다—예를 들어, 그래핌 클러스터에 비해. 우리가 아는 한, Python은 현재 후자에 대한 지원을 제공하지 않습니다.

따라서, 우리는 표현-불가지론적인 문자열 처리를 반대하며, 표현-투명한 API와 UTF-8 내부 표현을 선호합니다. 인덱싱 작업은 코드 포인트가 아닌 코드 유닛을 세는 것이며, 사실 변경 전에도 그렇게 했습니다. 이는 구현을 단순화하고 성능을 향상시킬 것이며, 예를 들어 웹을 다루는 스크립트에서 Python 프로그래밍 언어를 서버 측 세계에서 더 적용 가능하게 만들 것입니다. 스크립트 프로그래머가 문자열 자르기 작업의 안전성에 대해 논쟁할 수 있지만, 그래핌 클러스터를 분할하는 것도 마찬가지입니다. 유니코드가 이제 완전히 지원되지만, 우리는 현대적인 도구로서 역사적인 부담을 덜어야 하는 Python이 텍스트 처리에서 더 나은 작업을 해야 한다고 믿습니다.

그 외에도, JPython과 IronPython은 호스팅 플랫폼(각각 Java 및 .NET)에서 사용되는 덜 운이 좋은 인코딩에 계속 의존하며, 서로게이트 쌍을 올바르게 처리해야 합니다.

### [Q: 하지만 왜 `std::string`인가요? UTF-8을 인식하는 문자열 클래스를 갖는 것이 더 나은 객체 지향 접근 방식이 아닐까요?](#faq.ood)

A: 문자열을 다루는 모든 코드가 실제로 텍스트 처리 및 검증에 관여하는 것은 아닙니다. 유니코드 파일 이름을 받아 파일 IO 루틴에 전달하는 파일 복사 프로그램은 단순한 바이트 버퍼로도 충분할 것입니다. 문자열을 받아들이는 라이브러리를 설계한다면, 단순하고 표준적이며 가벼운 `std::string`이면 충분합니다. 반대로, 새로운 문자열 클래스를 재발명하고 모든 사람을 특이한 인터페이스를 통해 강제하는 것은 실수일 것입니다. 물론, 문자열을 전달하는 것 이상이 필요하다면 적절한 텍스트 처리 도구를 사용해야 합니다. 그러나 이러한 도구는 사용된 저장 클래스와 독립적인 것이 좋으며, STL의 컨테이너/알고리즘 분리 정신에 따라야 합니다. 사실, [일부는](http://www.gotw.ca/gotw/084.htm) `std::string` 인터페이스가 너무 부풀려져 있다고 생각하며, 대부분의 인터페이스는 `std::string` 클래스 외부로 이동하는 것이 더 나았을 것입니다.

### [Q: 이미 이 접근 방식을 사용하고 있으며 우리의 비전을 실현하고 싶습니다. 무엇을 할 수 있나요?](#faq.whats.now)

A: 말을 퍼뜨리십시오.

코드를 검토하고 휴대용 유니코드 인식 코드에서 가장 고통스러운 라이브러리가 무엇인지 확인하십시오. 작성자에게 버그 보고서를 여십시오. C 또는 C++ 라이브러리 작성자라면, `char*` 및 `std::string`을 UTF-8로 간주하고 ANSI 코드 페이지를 지원하지 마십시오—본질적으로 유니코드가 깨져 있기 때문입니다.

Microsoft 직원이라면, 좁은 API 코드 페이지 중 하나로 `CP_UTF8` 지원을 구현하도록 밀어붙이십시오.

추가 아이디어:

*   일반적으로 사용되는 타사 라이브러리(예: PugiXML, LibTIFF 등)에 대한 UTF-8 지원 패치 저장소를 만드십시오. 이들은 표준 C로 작성되었으며 Windows에 대해 신경 쓰지 않습니다.
*   Windows에서 표준 라이브러리 함수(예: `fopen()`)에 대한 링크 타임 패치를 만드십시오. 이는 적절한 매개변수 변환을 수행할 수 있습니다. 이는 `main()` 및 전역 환경 변수에 대해 수행할 수 있습니다.

[저자 소개](#about)
---------------------------

이 선언문은 [Pavel Radzivilovsky](http://meshnotes.com/9SrRpAypTr8e), [Yakov Galka](http://stannum.io/) 및 [Slava Novgorodov](http://slavanov.com/)가 작성했습니다. 이는 우리의 경험과 실제 프로그래머들이 저지른 유니코드 문제와 실수에 대한 연구의 결과입니다. 우리의 목표는 텍스트 문제에 대한 인식을 높이고, 유니코드 인식 프로그래밍을 더 쉽게 만들어 궁극적으로 인간 엔지니어가 작성한 프로그램의 사용자 경험을 개선하는 데 있습니다. 우리 중 누구도 유니코드 컨소시엄에 관여하지 않습니다.

Glenn Linderman에게 Python에 대한 정보를 제공해 주셔서 특별히 감사드리며, Markus Künne, Jelle Geerts, Lazy Rui 및 Jan Rüegg에게 이 문서의 버그와 오타를 보고해 주셔서 감사드립니다.

많은 텍스트는 [Artyom Beilis가 시작한 StackOverflow 토론](http://programmers.stackexchange.com/questions/102205/should-utf-16-be-considered-harmful)에서 영감을 받았으며, Boost.Locale의 저자입니다. 추가 영감은 [VisionMap](http://www.visionmap.com)의 개발 규칙과 Michael Hartl의 [tauday.org](http://tauday.com/tau-manifesto)에서 얻었습니다.

[외부 링크](#extern)
-------------------------

*   [유니코드 컨소시엄](http://www.unicode.org/) (유니코드 표준, [PDF](http://www.unicode.org/versions/Unicode6.2.0/UnicodeStandard-6.2.pdf))
*   [국제 유니코드 구성 요소](http://site.icu-project.org/) (ICU)
*   [Boost.Locale](http://cppcms.sourceforge.net/boost_locale/html/)—C++ 방식의 고품질 지역화 기능.
*   [UTF-16은 해롭다고 간주되어야 하는가](http://programmers.stackexchange.com/questions/102205/should-utf-16-be-considered-harmful) StackOverflow, Artyom Beilis가 시작함.
*   [트위터가 문자를 세는 방법](https://developer.twitter.com/en/docs/basics/counting-characters.html)


# 번역자 요약

### Q. 그래서 어떻게 하라는 이야기인가요?

UTF-8을 기본 내부 문자 인코딩으로 사용하세요. 전 세계적으로 가장 많이 쓰이는 형식이기 때문입니다.

1. **내부 저장 및 데이터 교환**  
   - 애플리케이션 내부에서는 문자열 데이터를 모두 UTF-8로 관리하세요.  
   - 파일 저장, 네트워크 통신 등에서도 UTF-8을 사용하면 다양한 문자(특히 비ASCII 문자)를 안전하게 처리할 수 있습니다.

2. **시스템 API와의 인터페이스**  
   - 예를 들어, Windows API는 내부적으로 UTF-16을 사용하므로, 시스템 호출 전후에 UTF-8↔UTF-16 변환을 해줘야 합니다.  
   - 이런 경우, 변환 함수를 한 곳에 모아두고, 그 외의 곳에서는 UTF-8 문자열만 다루는 것이 좋습니다. 

3. **문자 수 세기 및 커서 이동**  
   - “문자”의 정의는 애매한데, 단순히 코드 유닛(예: C/C++의 `char` 단위)나 코드 포인트 수를 세는 것은 사용자 입장에서 보이는 “문자”와 다를 수 있습니다.
   - 어떤 작업을 하느냐에 따라 ‘글자 수’의 정의(바이트/코드 유닛, 코드 포인트, 또는 그래핌 클러스터)가 달라진다는 사실을 기억하고, 목적에 맞게 적절한 단위를 사용해야 합니다.
   - 예를 들어, 저장공간 크기가 중요한 경우, 코드 유닛(혹은 단순한 바이트)수를 세는 것이 적절합니다.
   - 그러나 사용자가 인식하는 문자의 개수, 커서/방향키 이동의 경우 여러 코드 유닛으로 구성될 수 있는 그래핌 클러스터 단위를 사용하는 것이 적절합니다.

4. **라이브러리 사용 vs. 직접 구현**  
   - **직접 구현:**  
     - Unicode의 그래핌 클러스터, 코드 포인트 경계 등을 직접 구현하는 것은 매우 복잡하며, 잘못 구현할 위험이 큽니다.
   - **라이브러리 사용:**  
     - ICU, Boost.Locale, 혹은 최근에는 언어별로 제공되는 Unicode 처리 라이브러리(예: Python의 `unicodedata`, JavaScript의 Intl API 등)를 활용하는 것을 권장합니다.
     - 이런 라이브러리들은 이미 검증된 알고리즘(UAX #29 등)을 사용하여, 올바른 문자 단위 처리(문자 수 세기, 커서 이동, 텍스트 선택 등)를 지원합니다.

이런 방식으로 처리하면, 다국어 텍스트를 안정적으로 지원할 수 있고, 다양한 문자 인코딩 문제로부터 발생할 오류들을 최소화할 수 있습니다.
